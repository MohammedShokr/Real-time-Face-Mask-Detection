{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the needed liberairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# System\n",
    "import os\n",
    "import time\n",
    "import sys, datetime\n",
    "\n",
    "# CV\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imutils.video import FPS\n",
    "\n",
    "# DL\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "# Maths\n",
    "from statistics import mean, median\n",
    "\n",
    "# images and display\n",
    "import imutils\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from skimage import img_as_float\n",
    "from imutils.video import VideoStream\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREEN = (0, 255, 0)\n",
    "RED = (0, 0, 255)\n",
    "BLUE=(255, 0, 0)\n",
    "YELLOW = (0, 255, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory\n",
    "os.chdir(r\"\\Users\\messi\\OneDrive\\Desktop\\CIE\\Computer Vision\\Projects\\Final-Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading mask detection model\n",
    "loaded_model_0 = tf.keras.models.load_model('mask_detection_pretrained')\n",
    "# Loading mask status model\n",
    "loaded_model_1 = tf.keras.models.load_model('mask_status_pretrained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(img, flag=0):\n",
    "    # This function takes and image and a flag, it predicts the label of the image using\n",
    "    # the appropriate model based on the value of the flag (0: mask detection, 1: mask status)\n",
    "    \n",
    "    # Processing the image to be suitable for prediction\n",
    "    img_array = image.img_to_array(img)\n",
    "    camera_float = img_as_float(img_array)\n",
    "    img_batch = np.expand_dims(camera_float, axis=0)\n",
    "    img_preprocessed = tf.keras.applications.mobilenet_v2.preprocess_input(img_batch)\n",
    "    \n",
    "    # Mapping the label\n",
    "    if flag ==0:\n",
    "        prediction = loaded_model_0.predict(img_preprocessed)\n",
    "        pred = np.argmax(prediction,axis=1)\n",
    "        unique_labels = dict((v,k) for v,k in [(0,'with_mask'), (1,'without_mask')])\n",
    "    else:\n",
    "        prediction = loaded_model_1.predict(img_preprocessed)\n",
    "        pred = np.argmax(prediction,axis=1)\n",
    "        unique_labels = dict((v,k) for v,k in [(0,'Correct Mask'), (1,'Mask covers chin only'),(2,'Mask covers mouth and chin'),(3,'Mask covers mouth and nose')])\n",
    "        \n",
    "    pred = [unique_labels[k] for k in pred]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Start_Tracker(track_name, frame, face):\n",
    "    if track_name == \"KCF\": tracker = cv2.TrackerKCF_create()\n",
    "    elif track_name == \"CSRT\": tracker = cv2.TrackerCSRT_create()\n",
    "    elif track_name == \"MIL\": tracker = cv2.TrackerMIL_create()\n",
    "    tracker.init(frame, face)\n",
    "    return tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of Haar Cascades face detector\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection Only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture a video from webcam \n",
    "cap = cv2.VideoCapture(0)\n",
    "#time.sleep(2.0)\n",
    "# To use a video file as input \n",
    "#cap = cv2.VideoCapture(r'data\\output1.mkv')\n",
    "fps = FPS().start()\n",
    "while True:\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "    # Resize the frame to be of width 400\n",
    "    #img = imutils.resize(img, width=400)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect the faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    color = GREEN\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw rectangle around each face in the frame\n",
    "        cv2.rectangle(img, (x, y - 30), (x + w, y + h + 30), color, 2)\n",
    "        # Print the label on the image\n",
    "    fps.update()\n",
    "    fps.stop()\n",
    "    info = [\n",
    "        (\"Status\", \"Detecting\"),\n",
    "        (\"Detector\", \"Haar Cascades\"),\n",
    "        (\"FPS\", \"{:.2f}\".format(fps.fps())),\n",
    "    ]\n",
    "    for (i, (k, v)) in enumerate(info):\n",
    "        text = \"{}: {}\".format(k, v)\n",
    "        cv2.putText(img, text, (10, 300 - ((i * 20) + 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 0, 0), 1)\n",
    "    cv2.imshow('img', img)\n",
    "    # Stop if q key is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face detection and Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KCF Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture a video from webcam \n",
    "cap = cv2.VideoCapture(0)\n",
    "counter = 0\n",
    "fps = FPS().start()\n",
    "while True:\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "    # Resize the frame to be of width 400\n",
    "    #img = imutils.resize(img, width=400)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect the faces\n",
    "    if counter == 0:\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        trackers = [Start_Tracker(\"KCF\",img, face) for face in faces]\n",
    "        counter+=1\n",
    "    faces = [t.update(img)[1] for t in trackers]\n",
    "    if len(faces)==0:\n",
    "        counter = 0\n",
    "        continue\n",
    "    for (x, y, w, h) in faces:\n",
    "        if (x, y, w, h) == (0, 0, 0, 0):\n",
    "            counter = 0\n",
    "            break\n",
    "        # Draw rectangle around each face in the frame\n",
    "        cv2.rectangle(img, (x, y - 30), (x + w, y + h + 30), color, 2)\n",
    "        # Print the label on the image\n",
    "        color = GREEN if counter <= 1 else BLUE\n",
    "    fps.update()\n",
    "    fps.stop()\n",
    "    info = [\n",
    "        (\"Tracker\", \"KCF\"),\n",
    "        (\"Status\", \"Detecting\" if counter<=1 else \"Tracking\"),\n",
    "        (\"FPS\", \"{:.2f}\".format(fps.fps())),\n",
    "    ]\n",
    "    for (i, (k, v)) in enumerate(info):\n",
    "        text = \"{}: {}\".format(k, v)\n",
    "        cv2.putText(img, text, (10, 300 - ((i * 20) + 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 0, 0), 1)\n",
    "    cv2.imshow('img', img)\n",
    "    # Detect every 90 frames\n",
    "    if counter > 0 and counter < 90:\n",
    "        counter += 1\n",
    "    else:\n",
    "        counter = 0\n",
    "    # Stop if escape key is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSRT Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture a video from webcam \n",
    "cap = cv2.VideoCapture(0)\n",
    "counter = 0\n",
    "fps = FPS().start()\n",
    "while True:\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "    # Resize the frame to be of width 400\n",
    "    #img = imutils.resize(img, width=400)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect the faces\n",
    "    if counter == 0:\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        trackers = [Start_Tracker(\"CSRT\",img, face) for face in faces]\n",
    "        counter+=1\n",
    "    faces = [t.update(img)[1] for t in trackers]\n",
    "    if len(faces)==0:\n",
    "        counter = 0\n",
    "        continue\n",
    "    for (x, y, w, h) in faces:\n",
    "        if (x, y, w, h) == (0, 0, 0, 0):\n",
    "            counter = 0\n",
    "            break\n",
    "\n",
    "        roi = img[y - 30:y + h + 30, x:x + w]\n",
    "        # Resize the face to fit the shape of the input layer of mask detection model\n",
    "        roi = cv2.resize(roi, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "        roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        # Run mask detector on each face\n",
    "        # Draw rectangle around each face in the frame\n",
    "        cv2.rectangle(img, (x, y - 30), (x + w, y + h + 30), color, 2)\n",
    "        # Print the label on the image\n",
    "        color = GREEN if counter <= 1 else BLUE\n",
    "    fps.update()\n",
    "    fps.stop()\n",
    "    info = [\n",
    "        (\"Tracker\", \"CSRT\"),\n",
    "        (\"Status\", \"Detecting\" if counter<=1 else \"Tracking\"),\n",
    "        (\"FPS\", \"{:.2f}\".format(fps.fps())),\n",
    "    ]\n",
    "    for (i, (k, v)) in enumerate(info):\n",
    "        text = \"{}: {}\".format(k, v)\n",
    "        cv2.putText(img, text, (10, 300 - ((i * 20) + 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 0, 0), 1)\n",
    "    cv2.imshow('img', img)\n",
    "    # Detect every 90 frames\n",
    "    if counter > 0 and counter < 90:\n",
    "        counter += 1\n",
    "    else:\n",
    "        counter = 0\n",
    "    # Stop if q key is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIL Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture a video from webcam \n",
    "cap = cv2.VideoCapture(0)\n",
    "counter = 0\n",
    "fps = FPS().start()\n",
    "while True:\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "    # Resize the frame to be of width 400\n",
    "    #img = imutils.resize(img, width=400)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect the faces\n",
    "    if counter == 0:\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        trackers = [Start_Tracker(\"MIL\",img, face) for face in faces]\n",
    "        counter+=1\n",
    "    faces = [t.update(img)[1] for t in trackers]\n",
    "    if len(faces)==0:\n",
    "        counter = 0\n",
    "        continue\n",
    "    for (x, y, w, h) in faces:\n",
    "        if (x, y, w, h) == (0, 0, 0, 0):\n",
    "            counter = 0\n",
    "            break\n",
    "        # Draw rectangle around each face in the frame\n",
    "        cv2.rectangle(img, (x, y - 30), (x + w, y + h + 30), color, 2)\n",
    "        # Print the label on the image\n",
    "        color = GREEN if counter <= 1 else BLUE\n",
    "    fps.update()\n",
    "    fps.stop()\n",
    "    info = [\n",
    "        (\"Tracker\", \"MIL\"),\n",
    "        (\"Status\", \"Detecting\" if counter<=1 else \"Tracking\"),\n",
    "        (\"FPS\", \"{:.2f}\".format(fps.fps())),\n",
    "    ]\n",
    "    for (i, (k, v)) in enumerate(info):\n",
    "        text = \"{}: {}\".format(k, v)\n",
    "        cv2.putText(img, text, (10, 300 - ((i * 20) + 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 0, 0), 1)\n",
    "    cv2.imshow('img', img)\n",
    "    # Detect every 90 frames\n",
    "    if counter > 0 and counter < 90:\n",
    "        counter += 1\n",
    "    else:\n",
    "        counter = 0\n",
    "    # Stop if q key is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask Detection Model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture a video from webcam \n",
    "cap = cv2.VideoCapture(0)\n",
    "# To use a video file as input \n",
    "#cap = cv2.VideoCapture(r'data\\output1.mkv')\n",
    "counter = 0\n",
    "fps = FPS().start()\n",
    "while True:\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "    # Resize the frame to be of width 400\n",
    "    #img = imutils.resize(img, width=400)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect the faces\n",
    "    if counter == 0:\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        trackers = [Start_Tracker(\"KCF\",img, face) for face in faces]\n",
    "        counter+=1\n",
    "    faces = [t.update(img)[1] for t in trackers]\n",
    "    if len(faces)==0:\n",
    "        counter = 0\n",
    "        continue\n",
    "    for (x, y, w, h) in faces:\n",
    "        if (x, y, w, h) == (0, 0, 0, 0):\n",
    "            counter = 0\n",
    "            break\n",
    "\n",
    "        roi = img[y - 30:y + h + 30, x:x + w]\n",
    "        # Resize the face to fit the shape of the input layer of mask detection model\n",
    "        roi = cv2.resize(roi, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "        roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        # Run mask detector on each face\n",
    "        label = predict_class(roi_rgb, 0)\n",
    "        # Draw rectangle around each face in the frame\n",
    "        cv2.rectangle(img, (x, y - 30), (x + w, y + h + 30), color, 2)\n",
    "        # Print the label on the image\n",
    "        if label[0]==\"with_mask\": color=GREEN\n",
    "        else: color=RED\n",
    "        cv2.putText(img, label[0], (x, y - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "    fps.update()\n",
    "    fps.stop()\n",
    "    info = [\n",
    "        (\"Tracker\", \"KCF\"),\n",
    "        (\"Status\", \"Detecting\" if counter<=1 else \"Tracking\"),\n",
    "        (\"FPS\", \"{:.2f}\".format(fps.fps())),\n",
    "    ]\n",
    "    for (i, (k, v)) in enumerate(info):\n",
    "        text = \"{}: {}\".format(k, v)\n",
    "        cv2.putText(img, text, (10, 300 - ((i * 20) + 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 0, 0), 1)\n",
    "    cv2.imshow('img', img)\n",
    "    # Stop if escape key is pressed\n",
    "    if counter > 0 and counter < 90:\n",
    "        counter += 1\n",
    "    else:\n",
    "        counter = 0\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctly weared mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n"
     ]
    }
   ],
   "source": [
    "# Capture a video from webcam \n",
    "cap = cv2.VideoCapture(0)\n",
    "# To use a video file as input \n",
    "#cap = cv2.VideoCapture(r'data\\output3.mkv')\n",
    "#Find the number of frames with mask\n",
    "frames_mask = 21 * 30\n",
    "results=[]\n",
    "frames_per_second = cap.get(cv2.CAP_PROP_FPS)\n",
    "cur_frame = 0\n",
    "print(frames_per_second)\n",
    "counter = 0\n",
    "fps = FPS().start()\n",
    "while True:\n",
    "    cur_frame+=1\n",
    "    threshold = 20000\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect the faces\n",
    "    if counter == 0:\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        trackers = [Start_Tracker(\"KCF\",img, face) for face in faces]\n",
    "        counter+=1\n",
    "    color = RED\n",
    "    faces = [t.update(img)[1] for t in trackers]\n",
    "    if len(faces)==0:\n",
    "        counter = 0\n",
    "        continue\n",
    "    for (x, y, w, h) in faces:\n",
    "        if (x, y, w, h) == (0, 0, 0, 0):\n",
    "            counter = 0\n",
    "            break\n",
    "        if w*h <threshold:\n",
    "            counter = 0\n",
    "            break\n",
    "\n",
    "        roi = img[y - 30:y + h + 30, x:x + w]\n",
    "        # Resize the face to fit the shape of the input layer of mask detection model\n",
    "        roi = cv2.resize(roi, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "        roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        # Run mask detector on each face\n",
    "        label = predict_class(roi_rgb, 0)\n",
    "        # if the face is classified as wearing mask, check the mask status with the second model\n",
    "        if label[0] == \"with_mask\":\n",
    "            label = predict_class(roi_rgb, 1)\n",
    "            if label[0] == \"Correct Mask\": color = GREEN\n",
    "            else: color = YELLOW\n",
    "        # Draw rectangle around each face in the frame\n",
    "        cv2.rectangle(img, (x, y - 30), (x + w, y + h + 30), color, 2)\n",
    "        # Print the label on the image\n",
    "        if label[0]==\"Correct Mask\": results.append(1)\n",
    "        else: results.append(0)\n",
    "        cv2.putText(img, label[0], (x, y - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "    fps.update()\n",
    "    fps.stop()\n",
    "    info = [\n",
    "        (\"Tracker\", \"KCF\"),\n",
    "        (\"Status\", \"Detecting\" if counter<=1 else \"Tracking\"),\n",
    "        (\"FPS\", \"{:.2f}\".format(fps.fps())),\n",
    "    ]\n",
    "    for (i, (k, v)) in enumerate(info):\n",
    "        text = \"{}: {}\".format(k, v)\n",
    "        cv2.putText(img, text, (10, 300 - ((i * 20) + 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 0, 0), 1)\n",
    "    cv2.imshow('img', img)\n",
    "    # Stop if escape key is pressed\n",
    "    if counter > 0 and counter < 10:\n",
    "        counter += 1\n",
    "    else:\n",
    "        counter = 0\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Successive correct frames:  139\n"
     ]
    }
   ],
   "source": [
    "zeros=[i for i in range(len(results)) if results[i]==0]\n",
    "zeros.insert(0,0)\n",
    "diff=[zeros[j+1]-zeros[j] for j in range(len(zeros)-1)]\n",
    "print(\"Avg Successive correct frames: \",mean(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mask covers mouth and chin']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path=r\"C:\\Users\\messi\\OneDrive\\Desktop\\CIE\\Computer Vision\\Projects\\Final-Project\\data\\test8_effects.jpg\"\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "label=predict_class(img_array,1)\n",
    "label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
